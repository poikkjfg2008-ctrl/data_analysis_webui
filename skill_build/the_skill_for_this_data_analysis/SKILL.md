---
name: data-analysis-report
description: Generate comprehensive data analysis reports from Excel files using LLM-powered insights. Use when user asks to "analyze Excel data", "generate analysis report", "analyze trends in data", "compare metrics", or "create statistical report". Works offline with Ollama/vLLM. Outputs Word documents with charts and insights.
metadata:
  author: data-analysis-webui
  version: "2.0.0"
  license: MIT
---

# Data Analysis Report Generator

Automatically analyze Excel data and generate comprehensive Word reports with charts, statistics, and AI-powered insights. Works offline with Ollama or vLLM models.

## How It Works

1. **Excel Parsing** - Automatically detects date columns and numeric metrics
2. **Intent Understanding** - LLM parses your natural language request to extract metrics and time windows
3. **Indicator Disambiguation** - Handles multiple similar column names by asking for clarification
4. **Statistical Analysis** - Computes trends, percentiles, outliers, and correlations
5. **Report Generation** - Creates Word document with charts, tables, and AI-written insights

## Usage

```bash
python /mnt/skills/user/data-analysis-report/scripts/call_data_analysis_api.py \
  --base-url http://127.0.0.1:8001 \
  --excel-path /path/to/data.xlsx \
  --user-prompt "your analysis request here"
```

**Required Arguments:**
- `--base-url` - API server URL (default: `http://127.0.0.1:8001`)
- `--excel-path` - Absolute path to Excel file (.xlsx)
- `--user-prompt` - Natural language analysis request

**Optional Arguments:**
- `--sheet-name` - Specific sheet name (auto-detected if omitted)
- `--use-llm-structure` / `--no-use-llm-structure` - Use LLM for Excel structure detection (default: enabled)
- `--select-indicators` - Manually specify metrics (skips auto-disambiguation)
- `--timeout` - Request timeout in seconds (default: 120)

## Examples

### Basic Trend Analysis

```bash
python /mnt/skills/user/data-analysis-report/scripts/call_data_analysis_api.py \
  --base-url http://127.0.0.1:8001 \
  --excel-path /home/data/sales_2024.xlsx \
  --user-prompt "åˆ†ææœ€è¿‘ä¸€ä¸ªå­£åº¦çš„é”€é‡è¶‹åŠ¿"
```

### Multi-Metric Comparison

```bash
python /mnt/skills/user/data-analysis-report/scripts/call_data_analysis_api.py \
  --base-url http://127.0.0.1:8001 \
  --excel-path /home/data/production.xlsx \
  --user-prompt "åˆ†ææœ€è¿‘åŠå¹´äº§é‡å’Œé”€é‡çš„ç›¸å…³æ€§ï¼Œå¹¶ç»™å‡ºå»ºè®®"
```

### Specific Time Range

```bash
python /mnt/skills/user/data-analysis-report/scripts/call_data_analysis_api.py \
  --base-url http://127.0.0.1:8001 \
  --excel-path /home/data/financial.xlsx \
  --user-prompt "åˆ†æ 2024-01-01 è‡³ 2024-06-30 æœŸé—´çš„æ”¶å…¥ä¸æ”¯å‡º"
```

### Manual Metric Selection

```bash
python /mnt/skills/user/data-analysis-report/scripts/call_data_analysis_api.py \
  --base-url http://127.0.0.1:8001 \
  --excel-path /home/data/warehouse.xlsx \
  --user-prompt "åˆ†æåº“å­˜å‘¨è½¬æƒ…å†µ" \
  --select-indicators "åº“å­˜æ•°é‡" "å…¥åº“æ•°é‡" "å‡ºåº“æ•°é‡"
```

### With Custom Sheet and Timeout

```bash
python /mnt/skills/user/data-analysis-report/scripts/call_data_analysis_api.py \
  --base-url http://127.0.0.1:8001 \
  --excel-path /home/data/report.xlsx \
  --sheet-name "Q4 2024" \
  --user-prompt "åˆ†ææœ¬å­£åº¦æ‰€æœ‰æŒ‡æ ‡çš„è¡¨ç°" \
  --timeout 300
```

## Output

### Console Output

```bash
Preparing analysis...
âœ“ Health check passed
âœ“ Metrics matched: äº§é‡, é”€é‡
âœ“ Time window resolved: æœ€è¿‘ä¸€å¹´
âœ“ Analysis complete

Report saved to: /home/data/reports/report_20250301_143025.docx

Summary:
- Metrics: äº§é‡, é”€é‡
- Time window: æœ€è¿‘ä¸€å¹´ (2024-03-01 to 2025-03-01)
- Records: 365
- Sheet: Sheet1
```

### JSON Output (stdout)

```json
{
  "healthz": {"status": "ok"},
  "match": {
    "status": "ok",
    "indicator_names": ["äº§é‡", "é”€é‡"]
  },
  "selected_indicator_names": ["äº§é‡", "é”€é‡"],
  "analyze": {
    "report_path": "/home/data/reports/report_20250301_143025.docx",
    "time_window": {"type": "relative", "value": "æœ€è¿‘ä¸€å¹´"},
    "indicator_names": ["äº§é‡", "é”€é‡"],
    "sheet_name": "Sheet1",
    "date_column": "æ—¥æœŸ"
  }
}
```

### Generated Report Contents

The Word document (`.docx`) includes:
- **Time-series charts** for each metric with trend lines
- **Statistical summary table**: mean, min, max, median, std, P5, P95, CV, outliers
- **Period-over-period comparison**: start vs end values, absolute & % change
- **AI-generated insights**: trend analysis, anomaly detection, recommendations
- **Drift analysis**: linear regression slope for trend detection
- **Professional formatting**: Times New Roman (Latin), å®‹ä½“ (CJK)

## Excel File Requirements

**Required:**
- âœ… Must have a date column (auto-detected)
- âœ… Must have numeric metric columns
- âœ… First row must be column headers

**Supported:**
- âœ… Multiple sheets (auto-selects largest)
- âœ… Various date formats (Excel serial, ISO, etc.)
- âœ… Missing values (handled gracefully)
- âœ… Large files (100K+ rows with `use_llm_structure=false`)

**Not Supported:**
- âŒ Merged cells
- âŒ Pivot tables
- âŒ Protected sheets

## Time Window Formats

Supports both relative and absolute time ranges:

| Relative | Absolute |
|----------|----------|
| "æœ€è¿‘ä¸€å¹´" | "2024-01-01 è‡³ 2024-12-31" |
| "æœ€è¿‘åŠå¹´" | "2024 Q1 to 2024 Q2" |
| "æœ€è¿‘30å¤©" | "January 2024" |
| "æœ¬å­£åº¦" | "last week" |

## Metric Disambiguation Flow

When multiple similar column names exist (e.g., "äº§é‡", "åŠé’¢èƒäº§é‡", "å…¨é’¢èƒäº§é‡"):

```
User: "åˆ†æäº§é‡è¶‹åŠ¿"
â†“
System detects ambiguity â†’ Returns candidates
â†“
User selects: "äº§é‡", "åŠé’¢èƒäº§é‡"
â†“
Analysis proceeds with selected metrics
```

**To skip disambiguation**, use `--select-indicators` to specify exact column names.

## Present Results to User

Always present in this format:

```
âœ“ Analysis complete!

ğŸ“Š Report: /path/to/report_20250301_143025.docx
ğŸ“ˆ Metrics: äº§é‡, é”€é‡
ğŸ“… Period: æœ€è¿‘ä¸€å¹´ (2024-03-01 to 2025-03-01)
ğŸ“ Source: Sheet1

Key findings:
- äº§é‡å¹³å‡å€¼ä¸º 1050ï¼Œè¾ƒæœŸåˆå¢é•¿ 15.3%
- é”€é‡å‘ˆç°ä¸Šå‡è¶‹åŠ¿ï¼Œæ–œç‡ä¸º 2.3/å¤©
- ä¸¤æŒ‡æ ‡ç›¸å…³æ€§: 0.87 (å¼ºæ­£ç›¸å…³)

æ‰“å¼€ Word æ–‡æ¡£æŸ¥çœ‹å®Œæ•´å›¾è¡¨ä¸è¯¦ç»†åˆ†æã€‚
```

## API Server Setup

The skill requires a running Data Analysis API server:

### Quick Start

```bash
# 1. Install dependencies
cd /path/to/data_analysis_webui
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. Configure Ollama/vLLM (edit api/config.azure.json)
# Already configured for: http://172.24.16.1:11434 with qwen3:14b

# 3. Start server
uvicorn src.main:app --host 0.0.0.0 --port 8001

# 4. Verify
curl http://127.0.0.1:8001/healthz
```

### Background Service

```bash
# Start in background
nohup uvicorn src.main:app --host 0.0.0.0 --port 8001 > api.log 2>&1 &

# Check logs
tail -f api.log

# Stop service
pkill -f "uvicorn src.main:app"
```

## Troubleshooting

### Service Not Running

```
âŒ Error: Connection refused

Solution: Start the API server
  uvicorn src.main:app --host 0.0.0.0 --port 8001
```

### Ollama Connection Failed

```
âŒ Error: LLM request timeout

Solution: Check Ollama service
  curl http://172.24.16.1:11434/v1/models

If failing, ensure Ollama is running:
  ollama serve  # on Ollama machine
```

### Model Not Found

```
âŒ Error: model 'qwen3:14b' not found

Solution: Pull the model on Ollama machine
  ollama pull qwen3:14b
```

### Excel Parse Error

```
âŒ Error: æœªåŒ¹é…åˆ°æœ‰æ•ˆæŒ‡æ ‡åˆ—

Solution: Use --select-indicators to specify exact column names
  --select-indicators "äº§é‡" "é”€é‡"
```

### Timeout

```
âŒ Error: Timeout after 120s

Solution: Increase timeout for large files
  --timeout 600
```

### Common Errors Quick Reference

| Error | Cause | Fix |
|-------|-------|-----|
| `healthz` failed | API not started | `uvicorn src.main:app --host 0.0.0.0 --port 8001` |
| `match` returns `not_found` | Prompt too vague | Be specific about metric names |
| `analyze` returns 400 | File not found | Use absolute path, check file exists |
| `analyze` returns 400 | No data in time window | Check date range in Excel |
| LLM timeout | Model too slow | Increase `API_TIMEOUT_MS` in config |

## Advanced Configuration

### Environment Variables

```bash
# Override config file location
export DATA_ANALYSIS_CONFIG_PATH=/custom/config.json

# Override report output directory
export DATA_ANALYSIS_OUTPUT_DIR=/custom/output

# Override API timeout
# Edit api/config.azure.json: "API_TIMEOUT_MS": 1200000
```

### Model Selection

Edit `api/config.azure.json`:

```json
{
  "Providers": [{
    "name": "ollama",
    "api_base_url": "http://172.24.16.1:11434/v1",
    "models": ["qwen3:14b", "qwen2.5:32b"],  // Available models
    "context_window_chars": 128000
  }],
  "Router": { "default": "ollama,qwen3:14b" }  // Default model
}
```

### Context Window Tuning

For large Excel files (>10K rows):

```json
{
  "MODEL_CONTEXT_WINDOW_CHARS": 256000,  // Increase context
  "RAW_FILE_CONTEXT_RATIO": 0.5  // Allow more raw data
}
```

## Best Practices

### Writing Good Prompts

âœ… **Good prompts:**
- "åˆ†ææœ€è¿‘ä¸€å¹´äº§é‡å’Œé”€é‡çš„è¶‹åŠ¿ï¼Œæ¯”è¾ƒä¸¤è€…çš„ç›¸å…³æ€§"
- "åˆ†æ2024-01è‡³2024-06åº“å­˜å‘¨è½¬æƒ…å†µï¼Œæ‰¾å‡ºå¼‚å¸¸ç‚¹"
- "å¯¹æ¯”Q1å’ŒQ2çš„å„æŒ‡æ ‡è¡¨ç°ï¼Œç»™å‡ºæ”¹è¿›å»ºè®®"

âŒ **Poor prompts:**
- "åˆ†æä¸€ä¸‹" (too vague)
- "æœ€è¿‘æ€ä¹ˆæ ·" (no time range)
- "å¸®æˆ‘çœ‹çœ‹" (no metrics)

### For Large Files

```bash
# Disable LLM structure detection (faster, rule-based)
--no-use-llm-structure

# Increase timeout
--timeout 600
```

### For Batch Processing

```bash
# Process multiple files
for file in data/*.xlsx; do
  python scripts/call_data_analysis_api.py \
    --base-url http://127.0.0.1:8001 \
    --excel-path "$file" \
    --user-prompt "åˆ†ææ‰€æœ‰æŒ‡æ ‡çš„æœˆåº¦è¶‹åŠ¿"
done
```

## Integration Examples

### Python Script Integration

```python
import subprocess
import json

def analyze_excel(excel_path, prompt):
    result = subprocess.run([
        "python", "/mnt/skills/user/data-analysis-report/scripts/call_data_analysis_api.py",
        "--base-url", "http://127.0.0.1:8001",
        "--excel-path", excel_path,
        "--user-prompt", prompt
    ], capture_output=True, text=True)

    return json.loads(result.stdout)

# Usage
report_info = analyze_excel("/data/sales.xlsx", "åˆ†ææœ€è¿‘ä¸€å­£åº¦çš„é”€é‡è¶‹åŠ¿")
print(f"Report: {report_info['analyze']['report_path']}")
```

### Shell Script Integration

```bash
#!/bin/bash
analyze() {
  local file=$1
  local prompt=$2
  python /mnt/skills/user/data-analysis-report/scripts/call_data_analysis_api.py \
    --base-url http://127.0.0.1:8001 \
    --excel-path "$file" \
    --user-prompt "$prompt" | jq -r '.analyze.report_path'
}

# Usage
report_path=$(analyze "/data/sales.xlsx" "åˆ†æé”€é‡")
echo "Report saved to: $report_path"
```

## WebUI Alternative

For interactive multi-round analysis, use the Gradio WebUI:

```bash
python src/gradio_app.py
# Access at http://localhost:5600
```

WebUI features:
- File upload via browser
- Multi-turn conversation
- Report preview and download
- Comprehensive summary generation
- Iterative summary refinement

## See Also

- **Deployment Guide**: `DEPLOYMENT_GUIDE.md` - Complete server setup guide
- **Quick Start**: `QUICKSTART.md` - 5-minute getting started
- **API Documentation**: http://127.0.0.1:8001/docs (when server is running)
- **Project README**: `README.md` - Project overview
