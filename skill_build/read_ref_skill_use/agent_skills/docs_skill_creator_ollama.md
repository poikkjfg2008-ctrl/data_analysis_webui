# Skill Creator + Ollama 本地模型使用详解

本文档面向希望在本仓库中持续创建/维护 Skill 的开发者，重点说明：

1. `skill-creator`（元技能）的工作方式与价值
2. 如何把本仓库的 Skill 工作流迁移到你本地 `Ollama` 部署的模型上
3. 一套可直接执行的落地流程（从创建到打包）

---

## 1. 先理解：这个仓库里的 Skill 是什么

本仓库采用 Agent Skills 标准：每个 Skill 是一个独立目录，至少包含 `SKILL.md`，并可选带 `scripts/`、`references/`、`assets/`。这意味着 Skill 不只是 Prompt，而是「指令 + 流程 + 可执行脚本 + 参考资料」的组合包。对比传统函数调用，这种方式更适合复杂任务的可复用沉淀。

结合仓库规范，创建/更新 Skill 时要特别遵循：

- 目录名使用 `kebab-case`
- 必须有 `SKILL.md`
- 脚本建议放在 `scripts/`，并用 Bash + `set -e`
- 打包产物应为同名 zip：`{skill-name}.zip`

---

## 2. 什么是 Skill Creator（元技能）

`skill-creator` 本质是「用来生产 Skill 的 Skill」。它不是业务技能（例如部署、审计），而是一个工程化方法模板，专门指导 Agent 如何把用户需求变成标准化 Skill 包。

从该仓库的使用规范与可用技能描述看，`skill-creator` 的核心价值是：

- **把需求转成结构化产物**：名称、触发描述、执行流程、脚本边界
- **强调渐进式加载**：先用 `name + description` 触发，再按需加载正文/参考文件，降低上下文开销
- **控制“自由度”**：
  - 易变任务用文本指引（高自由度）
  - 半固定流程用伪代码/参数化脚本（中自由度）
  - 高风险任务用固定脚本（低自由度）
- **鼓励脚本化与复用**：重复逻辑尽量写进 `scripts/`，减少每次重写

你可以把它理解为一个“Skill 工程脚手架思维”：让 AI 不只是回答问题，而是产出可维护、可分发、可迭代的能力模块。

---

## 3. Skill 与 MCP 的关系（落地视角）

在实践中可按下面分层：

- **MCP / 工具层**：提供原子能力（读库、调 API、查日志）
- **Skill / 流程层**：定义“先做什么、后做什么、如何判断结果、如何呈现输出”

所以当你接入 Ollama 本地模型后，模型本身只是推理引擎；真正让 Agent 稳定做事的，是你沉淀下来的 Skill 流程与脚本。

---

## 4. 如何基于 Ollama 本地模型来使用本仓库

下面给一条“通用且稳妥”的路线，适合绝大多数本地部署场景。

### 4.1 模型与 API 接口准备

确保本地 Ollama 正常运行，并已有可用模型（例如通用指令模型或代码模型）。

典型检查：

```bash
ollama list
ollama serve
```

如果你的 Agent 框架支持 OpenAI 兼容接口，通常会通过 `base_url` 指向本地网关（常见是 `http://127.0.0.1:11434`，具体以你的部署为准）。

### 4.2 让 Agent 能读取 Skill 目录

将本仓库作为 Skill 源目录，保证 Agent 运行时可读：

- 读取 `skills/*/SKILL.md`
- 可执行 `skills/*/scripts/*.sh`
- 可访问 `references/`、`assets/` 等资源

如果你使用的是支持“技能目录”的 Agent 框架，关键是让它把 `skills/` 纳入可发现路径。

### 4.3 触发策略（强烈建议）

为了和本仓库设计一致，建议在你的 Agent 路由层实现三级策略：

1. **启动时只加载元数据**（name/description）
2. **匹配命中后加载对应 SKILL.md 正文**
3. **执行阶段按需调用脚本/参考文件**

这样即使本地模型上下文窗口较小，也能稳定运行复杂技能。

### 4.4 在 Ollama 场景下的模型选择建议

- **规划/文档型任务**：选对中文和结构化输出更稳的通用模型
- **脚本/代码型任务**：优先代码专长模型
- **长流程任务**：优先上下文更长且遵循指令稳定的模型

建议做一个最小基准集（3~5 个真实任务），评估：

- 触发准确率（是否命中正确 Skill）
- 脚本调用成功率
- 输出格式稳定性
- 总 token 与响应延迟

---

## 5. 在本仓库内创建新 Skill（结合 skill-creator 思路）

### Step 1：定义触发语句与边界

先写清楚“用户会怎么说”。例如：

- “帮我审查这个 PR 的前端性能风险”
- “把这批日志做异常聚类并给出根因建议”

然后明确：

- 输入是什么
- 输出是什么
- 哪些步骤必须脚本化

### Step 2：初始化目录

```text
skills/
  your-skill-name/
    SKILL.md
    scripts/
      run.sh
```

### Step 3：写 SKILL.md（控制在精简范围）

建议只放：

- 触发条件
- 主流程
- 参数说明
- 结果呈现模板
- 何时读取 references

把大段细则放入 `references/`，避免正文膨胀。

### Step 4：脚本化高重复步骤

脚本建议遵循：

- `#!/bin/bash`
- `set -e`
- 状态日志走 stderr
- 机器可解析结果走 stdout（JSON）

### Step 5：打包

```bash
cd skills
zip -r your-skill-name.zip your-skill-name/
```

### Step 6：在 Ollama Agent 中回归验证

至少验证三类场景：

1. 正常输入（应命中并成功输出）
2. 参数缺失（应给出可操作提示）
3. 工具失败（应有降级或报错说明）

---

## 6. 推荐的“本地模型 + Skill 库”迭代机制

为了让你的本地 Agent 越用越强，建议维护一个轻量循环：

1. **记录失败案例**（触发错、脚本错、格式错）
2. **判断归因**（模型能力问题 vs Skill 设计问题）
3. **优先改 Skill**（补触发短语、补流程、补异常处理）
4. **再考虑换模型**（必要时）

经验上，很多“模型不聪明”问题，最终都可以通过更好的 Skill 结构和脚本边界解决。

---

## 7. 给你的可执行清单（Checklist）

- [ ] Ollama 服务与模型可用
- [ ] Agent 已接入本地模型 API
- [ ] Agent 可发现 `skills/` 目录
- [ ] 已实现元数据优先、正文按需加载
- [ ] 新 Skill 遵循 `SKILL.md + scripts/ + zip` 规范
- [ ] 至少完成 3 条真实任务回归

当以上都满足后，你就拥有了一个可离线运行、可持续演进、可复用分享的本地 Skill 工程体系。

---

## 8. 附：给团队的实践建议

- 把 Skill 当“可维护资产”，不是一次性 Prompt
- 优先沉淀高频流程（部署、巡检、审计、报表）
- 用版本控制管理 Skill 演进（说明每次改动提升了什么）
- 小步快跑：每次只优化一个触发或一个脚本路径

如果你愿意，我下一步可以按你现有 Ollama 模型（名称、上下文长度、推理速度）帮你给出一份“模型-任务匹配矩阵”，并提供一个可直接复用的 `SKILL.md` 模板（中文优化版）。
